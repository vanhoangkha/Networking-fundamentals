#!/usr/bin/env python3
"""
Script ki·ªÉm tra ch·∫•t l∆∞·ª£ng to√†n di·ªán cho t√†i li·ªáu CCNA
Bao g·ªìm format, vƒÉn phong, markdown, v√† t√≠nh nh·∫•t qu√°n
"""

import os
import re
import glob
from pathlib import Path
from collections import defaultdict

class ComprehensiveQualityChecker:
    def __init__(self):
        self.issues = defaultdict(list)
        self.stats = defaultdict(int)
        
        # T·ª´ ƒëi·ªÉn thu·∫≠t ng·ªØ chu·∫©n
        self.standard_terms = {
            'switch': 'switch',
            'router': 'router',
            'firewall': 't∆∞·ªùng l·ª≠a',
            'ethernet': 'Ethernet',
            'internet': 'Internet',
            'tcp': 'TCP',
            'udp': 'UDP',
            'ip': 'IP',
            'ipv4': 'IPv4',
            'ipv6': 'IPv6',
            'lan': 'LAN',
            'wan': 'WAN',
            'vlan': 'VLAN',
            'dns': 'DNS',
            'dhcp': 'DHCP',
            'http': 'HTTP',
            'https': 'HTTPS',
            'ftp': 'FTP',
            'ssh': 'SSH',
            'cli': 'CLI',
            'gui': 'GUI',
            'api': 'API',
            'osi': 'OSI',
            'cisco': 'Cisco',
            'ieee': 'IEEE'
        }
        
        # L·ªói ch√≠nh t·∫£ ph·ªï bi·∫øn
        self.common_typos = {
            'thi√™t b·ªã': 'thi·∫øt b·ªã',
            'mang': 'm·∫°ng',
            'k√™t n·ªëi': 'k·∫øt n·ªëi',
            'truy√™n': 'truy·ªÅn',
            'c·∫•u hinh': 'c·∫•u h√¨nh',
            'giao th∆∞c': 'giao th·ª©c',
            'ƒë·ªãnh tuyen': 'ƒë·ªãnh tuy·∫øn',
            'b·∫£o m√¢t': 'b·∫£o m·∫≠t',
            'ph·∫ßn m√™m': 'ph·∫ßn m·ªÅm'
        }
        
        # C·ª•m t·ª´ c·∫ßn c·∫£i thi·ªán vƒÉn phong
        self.style_improvements = {
            'ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ': 'd√πng ƒë·ªÉ',
            'c√≥ th·ªÉ ƒë∆∞·ª£c': 'c√≥ th·ªÉ',
            'l√† m·ªôt': 'l√†',
            'trong tr∆∞·ªùng h·ª£p': 'khi',
            'b·ªüi v√¨': 'v√¨',
            'do ƒë√≥ m√†': 'do ƒë√≥',
            'tuy nhi√™n': 'nh∆∞ng',
            'm·∫∑c d√π v·∫≠y': 'tuy v·∫≠y'
        }

    def check_file_structure(self, content, filename):
        """Ki·ªÉm tra c·∫•u tr√∫c file"""
        issues = []
        
        # Ki·ªÉm tra header ch√≠nh
        if not content.startswith('# NG√ÄY'):
            issues.append("Thi·∫øu header ch√≠nh 'NG√ÄY XX:'")
        
        # Ki·ªÉm tra sections
        sections = re.findall(r'^## \d+\.\d+ (.+)', content, re.MULTILINE)
        if len(sections) < 2:
            issues.append("Qu√° √≠t sections (n√™n c√≥ √≠t nh·∫•t 2 sections)")
        
        # Ki·ªÉm tra subsections
        subsections = re.findall(r'^### \d+\.\d+\.\d+ (.+)', content, re.MULTILINE)
        
        return issues

    def check_markdown_syntax(self, content):
        """Ki·ªÉm tra markdown syntax"""
        issues = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # Ki·ªÉm tra headers
            if line.startswith('#'):
                if not re.match(r'^#+\s+', line):
                    issues.append(f"D√≤ng {i}: Header thi·∫øu space sau #")
            
            # Ki·ªÉm tra lists
            if re.match(r'^\s*[-*+]\s*$', line):
                issues.append(f"D√≤ng {i}: List item tr·ªëng")
            
            # Ki·ªÉm tra bold/italic
            if '**' in line:
                if line.count('**') % 2 != 0:
                    issues.append(f"D√≤ng {i}: Bold text kh√¥ng ƒë√≥ng ƒë√∫ng")
            
            # Ki·ªÉm tra links
            if '[' in line and ']' in line:
                if not re.search(r'\[([^\]]+)\]\(([^)]+)\)', line):
                    if '[' in line and ']' in line and '(' in line and ')' in line:
                        issues.append(f"D√≤ng {i}: Link syntax c√≥ th·ªÉ sai")
        
        return issues

    def check_spelling(self, content):
        """Ki·ªÉm tra ch√≠nh t·∫£"""
        issues = []
        
        for wrong, correct in self.common_typos.items():
            if wrong in content:
                count = content.count(wrong)
                issues.append(f"L·ªói ch√≠nh t·∫£: '{wrong}' ‚Üí '{correct}' ({count} l·∫ßn)")
        
        return issues

    def check_terminology(self, content):
        """Ki·ªÉm tra thu·∫≠t ng·ªØ k·ªπ thu·∫≠t"""
        issues = []
        
        for term_lower, term_correct in self.standard_terms.items():
            # T√¨m c√°c bi·∫øn th·ªÉ sai
            pattern = r'\b' + re.escape(term_lower) + r'\b'
            matches = re.findall(pattern, content, re.IGNORECASE)
            
            for match in matches:
                if match != term_correct:
                    issues.append(f"Thu·∫≠t ng·ªØ: '{match}' n√™n l√† '{term_correct}'")
        
        return issues

    def check_style(self, content):
        """Ki·ªÉm tra vƒÉn phong"""
        issues = []
        
        for old_phrase, new_phrase in self.style_improvements.items():
            if old_phrase in content:
                count = content.count(old_phrase)
                issues.append(f"VƒÉn phong: '{old_phrase}' ‚Üí '{new_phrase}' ({count} l·∫ßn)")
        
        # Ki·ªÉm tra c√¢u qu√° d√†i
        sentences = re.split(r'[.!?]+', content)
        for sentence in sentences:
            if len(sentence.strip()) > 200:
                issues.append(f"C√¢u qu√° d√†i ({len(sentence)} k√Ω t·ª±): {sentence[:50]}...")
        
        return issues

    def check_consistency(self, content):
        """Ki·ªÉm tra t√≠nh nh·∫•t qu√°n"""
        issues = []
        
        # Ki·ªÉm tra bullet points
        bullet_types = set()
        for line in content.split('\n'):
            if re.match(r'^\s*[-*+‚Ä¢]\s', line):
                bullet_char = re.match(r'^\s*([-*+‚Ä¢])', line).group(1)
                bullet_types.add(bullet_char)
        
        if len(bullet_types) > 1:
            issues.append(f"Bullet points kh√¥ng nh·∫•t qu√°n: {bullet_types}")
        
        # Ki·ªÉm tra c√°ch vi·∫øt s·ªë
        numbers = re.findall(r'\d+\s*(byte|bit|Mbps|Gbps|km|m)', content)
        if numbers:
            # Ki·ªÉm tra c√≥ space gi·ªØa s·ªë v√† ƒë∆°n v·ªã
            for match in re.finditer(r'\d+(byte|bit|Mbps|Gbps|km|m)', content):
                issues.append(f"Thi·∫øu space gi·ªØa s·ªë v√† ƒë∆°n v·ªã: {match.group()}")
        
        return issues

    def check_readability(self, content):
        """Ki·ªÉm tra kh·∫£ nƒÉng ƒë·ªçc"""
        issues = []
        
        # ƒê·∫øm t·ª´ v√† c√¢u
        words = len(re.findall(r'\b\w+\b', content))
        sentences = len(re.findall(r'[.!?]+', content))
        
        if sentences > 0:
            avg_words_per_sentence = words / sentences
            if avg_words_per_sentence > 25:
                issues.append(f"C√¢u trung b√¨nh qu√° d√†i ({avg_words_per_sentence:.1f} t·ª´/c√¢u)")
        
        # Ki·ªÉm tra ƒëo·∫°n vƒÉn qu√° d√†i
        paragraphs = content.split('\n\n')
        for i, para in enumerate(paragraphs):
            if len(para.strip()) > 1000:
                issues.append(f"ƒêo·∫°n {i+1} qu√° d√†i ({len(para)} k√Ω t·ª±)")
        
        return issues

    def analyze_file(self, file_path):
        """Ph√¢n t√≠ch m·ªôt file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            filename = os.path.basename(file_path)
            
            # Th·ª±c hi·ªán c√°c ki·ªÉm tra
            structure_issues = self.check_file_structure(content, filename)
            markdown_issues = self.check_markdown_syntax(content)
            spelling_issues = self.check_spelling(content)
            terminology_issues = self.check_terminology(content)
            style_issues = self.check_style(content)
            consistency_issues = self.check_consistency(content)
            readability_issues = self.check_readability(content)
            
            # T·ªïng h·ª£p k·∫øt qu·∫£
            all_issues = {
                'structure': structure_issues,
                'markdown': markdown_issues,
                'spelling': spelling_issues,
                'terminology': terminology_issues,
                'style': style_issues,
                'consistency': consistency_issues,
                'readability': readability_issues
            }
            
            # C·∫≠p nh·∫≠t th·ªëng k√™
            total_issues = sum(len(issues) for issues in all_issues.values())
            self.stats['total_files'] += 1
            self.stats['total_issues'] += total_issues
            
            if total_issues == 0:
                self.stats['perfect_files'] += 1
            
            return {
                'file': filename,
                'issues': all_issues,
                'total_issues': total_issues,
                'word_count': len(re.findall(r'\b\w+\b', content)),
                'line_count': len(content.split('\n'))
            }
            
        except Exception as e:
            return {
                'file': os.path.basename(file_path),
                'error': str(e),
                'total_issues': 0
            }

    def generate_report(self, results):
        """T·∫°o b√°o c√°o chi ti·∫øt"""
        report = []
        report.append("# B√ÅO C√ÅO KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG TO√ÄN DI·ªÜN\n")
        report.append(f"**Ng√†y ki·ªÉm tra**: {os.popen('date').read().strip()}\n")
        
        # Th·ªëng k√™ t·ªïng quan
        report.append("## üìä Th·ªëng k√™ t·ªïng quan\n")
        report.append(f"- **T·ªïng s·ªë file**: {self.stats['total_files']}")
        report.append(f"- **File ho√†n h·∫£o**: {self.stats['perfect_files']}")
        report.append(f"- **T·ªïng v·∫•n ƒë·ªÅ**: {self.stats['total_issues']}")
        report.append(f"- **T·ª∑ l·ªá ho√†n h·∫£o**: {self.stats['perfect_files']/self.stats['total_files']*100:.1f}%\n")
        
        # Ph√¢n lo·∫°i v·∫•n ƒë·ªÅ
        issue_categories = defaultdict(int)
        for result in results:
            if 'issues' in result:
                for category, issues in result['issues'].items():
                    issue_categories[category] += len(issues)
        
        report.append("## üîç Ph√¢n lo·∫°i v·∫•n ƒë·ªÅ\n")
        for category, count in sorted(issue_categories.items(), key=lambda x: x[1], reverse=True):
            report.append(f"- **{category.title()}**: {count} v·∫•n ƒë·ªÅ")
        report.append("")
        
        # Top file c√≥ nhi·ªÅu v·∫•n ƒë·ªÅ nh·∫•t
        problematic_files = [r for r in results if r.get('total_issues', 0) > 0]
        problematic_files.sort(key=lambda x: x.get('total_issues', 0), reverse=True)
        
        if problematic_files:
            report.append("## ‚ö†Ô∏è File c·∫ßn ch√∫ √Ω nh·∫•t\n")
            for result in problematic_files[:10]:
                report.append(f"- **{result['file']}**: {result['total_issues']} v·∫•n ƒë·ªÅ")
            report.append("")
        
        # File ho√†n h·∫£o
        perfect_files = [r for r in results if r.get('total_issues', 0) == 0]
        if perfect_files:
            report.append("## ‚úÖ File ho√†n h·∫£o\n")
            for result in perfect_files[:10]:
                report.append(f"- {result['file']}")
            if len(perfect_files) > 10:
                report.append(f"- ... v√† {len(perfect_files) - 10} file kh√°c")
            report.append("")
        
        # Chi ti·∫øt t·ª´ng file
        report.append("## üìã Chi ti·∫øt t·ª´ng file\n")
        for result in results:
            report.append(f"### {result['file']}\n")
            
            if result.get('error'):
                report.append(f"‚ùå **L·ªói**: {result['error']}\n")
                continue
            
            if result.get('total_issues', 0) == 0:
                report.append("‚úÖ **Ho√†n h·∫£o** - Kh√¥ng c√≥ v·∫•n ƒë·ªÅ\n")
                continue
            
            report.append(f"**T·ªïng v·∫•n ƒë·ªÅ**: {result['total_issues']}")
            report.append(f"**S·ªë t·ª´**: {result.get('word_count', 0)}")
            report.append(f"**S·ªë d√≤ng**: {result.get('line_count', 0)}\n")
            
            for category, issues in result.get('issues', {}).items():
                if issues:
                    report.append(f"**{category.title()}**:")
                    for issue in issues[:5]:  # Ch·ªâ hi·ªÉn th·ªã 5 v·∫•n ƒë·ªÅ ƒë·∫ßu
                        report.append(f"- {issue}")
                    if len(issues) > 5:
                        report.append(f"- ... v√† {len(issues) - 5} v·∫•n ƒë·ªÅ kh√°c")
                    report.append("")
        
        return '\n'.join(report)

def main():
    checker = ComprehensiveQualityChecker()
    base_dir = "/home/ubuntu/NEO/Networking fundamentals"
    pattern = os.path.join(base_dir, "Day*.md")
    files = glob.glob(pattern)
    
    print("üîç KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG TO√ÄN DI·ªÜN")
    print("=" * 50)
    
    results = []
    
    for file_path in sorted(files):
        result = checker.analyze_file(file_path)
        results.append(result)
        
        filename = result['file']
        total_issues = result.get('total_issues', 0)
        
        if result.get('error'):
            print(f"‚ùå {filename}: L·ªói - {result['error']}")
        elif total_issues == 0:
            print(f"‚úÖ {filename}: Ho√†n h·∫£o")
        else:
            print(f"‚ö†Ô∏è  {filename}: {total_issues} v·∫•n ƒë·ªÅ")
    
    # T·∫°o b√°o c√°o
    report_content = checker.generate_report(results)
    report_path = os.path.join(base_dir, "COMPREHENSIVE_QUALITY_REPORT.md")
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print("\n" + "=" * 50)
    print("üìä T·ªîNG K·∫æT:")
    print(f"‚úÖ ƒê√£ ki·ªÉm tra: {checker.stats['total_files']} file")
    print(f"üèÜ File ho√†n h·∫£o: {checker.stats['perfect_files']} file")
    print(f"‚ö†Ô∏è  T·ªïng v·∫•n ƒë·ªÅ: {checker.stats['total_issues']}")
    print(f"üìà T·ª∑ l·ªá ho√†n h·∫£o: {checker.stats['perfect_files']/checker.stats['total_files']*100:.1f}%")
    print(f"üìã B√°o c√°o chi ti·∫øt: COMPREHENSIVE_QUALITY_REPORT.md")

if __name__ == "__main__":
    main()
